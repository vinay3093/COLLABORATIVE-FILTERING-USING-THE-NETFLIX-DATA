{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id,row_number \n",
    "\n",
    "from pyspark.sql.functions import isnan, count, when, col, desc, udf, col,rand\n",
    "from pyspark.sql.functions import sort_array, asc, avg\n",
    "from pyspark.sql.functions import min as Fmin\n",
    "from pyspark.sql.functions import max as Fmax\n",
    "from pyspark.sql.functions import stddev as Fstddev\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "from pyspark.sql.functions import rank \n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrameStatFunctions as statFunc\n",
    "from pyspark.sql.functions import first\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import correlation\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os, sys\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_filename ='TrainingRatings.txt'\n",
    "Testing_filename = 'TestingRatings.txt'\n",
    "Movie_filename = 'movie_titles.txt'\n",
    "#'s3://netflixfinal/movie_titles.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "movies_df_schema = StructType(\n",
    "  [StructField('movieId', IntegerType()),\n",
    "   StructField('yearofrelease', IntegerType()),\n",
    "   StructField('title', StringType())]\n",
    ")\n",
    "Training_df_schema = StructType(\n",
    "  [StructField('movieId', IntegerType()),\n",
    "   StructField('userId', IntegerType()),\n",
    "   StructField('ratings',DoubleType())]\n",
    ")\n",
    "\n",
    "Testing_df_schema = StructType(\n",
    "  [StructField('movieId', IntegerType()),\n",
    "   StructField('userId', IntegerType()),\n",
    "   StructField('ratings',DoubleType())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3255352 samples in training set , 100478 samples in testing set and 17770 samples in movies in the datasets\n",
      "Training:\n",
      "+-------+-------+-------+\n",
      "|movieId| userId|ratings|\n",
      "+-------+-------+-------+\n",
      "|      8|1744889|    1.0|\n",
      "|      8|1395430|    2.0|\n",
      "|      8|1205593|    4.0|\n",
      "|      8|1488844|    4.0|\n",
      "|      8|1447354|    1.0|\n",
      "+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Testing:\n",
      "+-------+-------+-------+\n",
      "|movieId| userId|ratings|\n",
      "+-------+-------+-------+\n",
      "|      8| 573364|    1.0|\n",
      "|      8|2149668|    3.0|\n",
      "|      8|1089184|    3.0|\n",
      "|      8|2465894|    3.0|\n",
      "|      8| 534508|    1.0|\n",
      "+-------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Movies:\n",
      "+-------+-------------+----------------------------+\n",
      "|movieId|yearofrelease|title                       |\n",
      "+-------+-------------+----------------------------+\n",
      "|1      |2003         |Dinosaur Planet             |\n",
      "|2      |2004         |Isle of Man TT 2004 Review  |\n",
      "|3      |1997         |Character                   |\n",
      "|4      |1994         |Paula Abdul's Get Up & Dance|\n",
      "|5      |2004         |The Rise and Fall of ECW    |\n",
      "+-------+-------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating the training,testing and movie dataframes\n",
    "\n",
    "df_training = sqlContext.read.format('txt').options(inferSchema=True).schema(Training_df_schema).csv(Training_filename)\n",
    " \n",
    "df_testing = sqlContext.read.format('txt').options(inferSchema=True).schema(Testing_df_schema).csv(Testing_filename)\n",
    " \n",
    "df_movies = sqlContext.read.format('txt').options(inferSchema=True).schema(movies_df_schema).csv(Movie_filename)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#Count of each dataframes     \n",
    "training_count = df_training.count()\n",
    "testing_count = df_testing.count()\n",
    "movies_count = df_movies.count()\n",
    "\n",
    "\n",
    "print('There are %s samples in training set , %s samples in testing set and %s samples in movies in the datasets' % (training_count,testing_count, movies_count))\n",
    "print('Training:')\n",
    "df_training.show(5)\n",
    "print('Testing:')\n",
    "df_testing.show(5)\n",
    "print('Movies:')\n",
    "df_movies.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distinct users in training set are : 28978\n",
      "The distinct users in testing set are : 27555\n"
     ]
    }
   ],
   "source": [
    "## HOW MANY DISTINCT USERS AND DISTINCT ITEMS ARE THERE IN THE TEST SET ?\n",
    "#finding out the distinct users in the training set and testing set \n",
    "\n",
    "print(\"The distinct users in training set are :\",df_training.select('userID').distinct().count())\n",
    "print(\"The distinct users in testing set are :\",df_testing.select('userID').distinct().count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distinct items in training set are : 1821\n",
      "The distinct items in testing set are : 1701\n"
     ]
    }
   ],
   "source": [
    "#finding out the distinct items(movies) in the training set and testing set \n",
    "\n",
    "print(\"The distinct items in training set are :\",df_training.select('movieID').distinct().count())\n",
    "print(\"The distinct items in testing set are :\",df_testing.select('movieID').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|movieId|     avg(ratings)|\n",
      "+-------+-----------------+\n",
      "|   3033|              4.5|\n",
      "|  12293|4.464598134454594|\n",
      "|  16147|4.422818791946309|\n",
      "|  14283|4.418618618618619|\n",
      "|   1256|4.414830736163353|\n",
      "|   5760|4.410690051153565|\n",
      "|   7569| 4.38388625592417|\n",
      "|   4238|4.372822299651568|\n",
      "|  14648| 4.35288414929714|\n",
      "|   3290|4.339868147120056|\n",
      "|  10947|4.339148474704135|\n",
      "|  10080|4.318296583066823|\n",
      "|   7016|4.318181818181818|\n",
      "|  17085|4.283419689119171|\n",
      "|   3928|4.234884732492388|\n",
      "|   4207|4.234758013827781|\n",
      "|  12184|4.230476707863643|\n",
      "|  15557|4.218554861730597|\n",
      "|   7445|4.198757763975156|\n",
      "|    634|4.195422535211268|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding Overall Rates for users and Movies in both the sets\n",
    "## Movie Rating from Training Set\n",
    "#checking overall rate of the movies  in the training set\n",
    "\n",
    "Movie_rate_train = df_training.groupBy('movieId')\n",
    "\n",
    "Movie_rate_train.avg('ratings').orderBy(\"avg(ratings)\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "| userId|      avg(ratings)|\n",
      "+-------+------------------+\n",
      "| 336578|               5.0|\n",
      "|1482568|               5.0|\n",
      "|2451667|               5.0|\n",
      "| 784490|               5.0|\n",
      "|2307226|               5.0|\n",
      "|1663569|               5.0|\n",
      "|1309838|               5.0|\n",
      "|1193505|               5.0|\n",
      "|1745577|               5.0|\n",
      "| 396595|               5.0|\n",
      "| 794999| 4.996108949416342|\n",
      "|1379159| 4.989247311827957|\n",
      "| 175935| 4.987341772151899|\n",
      "| 642384| 4.987179487179487|\n",
      "|1299754| 4.987179487179487|\n",
      "|2635943| 4.982142857142857|\n",
      "| 132333| 4.977777777777778|\n",
      "|  27318|4.9753086419753085|\n",
      "|1293835|4.9753086419753085|\n",
      "| 223526|  4.97457627118644|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## User Rating from Training Set\n",
    "\n",
    "\n",
    "User_rate_train = df_training.groupBy('userId')\n",
    "User_rate_train.avg('ratings').orderBy(\"avg(ratings)\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|movieID|avg(ratings)|\n",
      "+-------+------------+\n",
      "|   3033|         5.0|\n",
      "|  13760|         5.0|\n",
      "|  12695|         5.0|\n",
      "|   6830|         5.0|\n",
      "|  10404|         5.0|\n",
      "|  13989|         5.0|\n",
      "|  15536|         5.0|\n",
      "|  12544|         5.0|\n",
      "|  11657|         5.0|\n",
      "|  13606|         5.0|\n",
      "|   7823|         5.0|\n",
      "|  12705|         5.0|\n",
      "|   3164|         5.0|\n",
      "|   3722|         5.0|\n",
      "|  10743|         5.0|\n",
      "|   5225|         5.0|\n",
      "|   9930|         5.0|\n",
      "|  11159|         5.0|\n",
      "|  13965|         5.0|\n",
      "|   9920|         5.0|\n",
      "+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Movie Ratings from Testing Set\n",
    "\n",
    "\n",
    "#checking overall rate of the movies  in the testing set\n",
    "Movie_rate_test = df_testing.groupBy('movieID')\n",
    "Movie_rate_test.avg('ratings').orderBy(\"avg(ratings)\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "| userID|      avg(ratings)|\n",
      "+-------+------------------+\n",
      "| 336578|               5.0|\n",
      "|1663569|               5.0|\n",
      "|2307226|               5.0|\n",
      "|1193505|               5.0|\n",
      "|1482568|               5.0|\n",
      "| 784490|               5.0|\n",
      "|1309838|               5.0|\n",
      "|2451667|               5.0|\n",
      "|1745577|               5.0|\n",
      "| 396595|               5.0|\n",
      "| 794999| 4.996108949416342|\n",
      "|1379159| 4.989247311827957|\n",
      "| 175935| 4.987341772151899|\n",
      "| 642384| 4.987179487179487|\n",
      "|1299754| 4.987179487179487|\n",
      "|2635943| 4.982142857142857|\n",
      "| 132333| 4.977777777777778|\n",
      "|1293835|4.9753086419753085|\n",
      "|  27318|4.9753086419753085|\n",
      "| 223526|  4.97457627118644|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## User Ratings from Testing Set\n",
    "\n",
    "User_rate_test = df_training.groupBy('userID')\n",
    "User_rate_test.avg('ratings').orderBy(\"avg(ratings)\", ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|   6971|  811|\n",
      "|   4640|  756|\n",
      "|   6287|  737|\n",
      "|   9728|  706|\n",
      "|   8915|  695|\n",
      "|   4432|  692|\n",
      "|   8596|  691|\n",
      "|   6408|  680|\n",
      "|   1406|  652|\n",
      "|   1744|  650|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "This user has watched this much movies\n"
     ]
    }
   ],
   "source": [
    "#Identifying the number of users have watched each movie from the testing set\n",
    "\n",
    "df_testing.groupBy('movieId').count().orderBy(\"count\", ascending=False).show(10)\n",
    "\n",
    "print(\"This user has watched this much movies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "| userId|count|\n",
      "+-------+-----+\n",
      "|1664010|   70|\n",
      "| 305344|   52|\n",
      "|2439493|   52|\n",
      "| 387418|   51|\n",
      "|1314869|   38|\n",
      "|2118461|   34|\n",
      "|1932594|   28|\n",
      "| 491531|   27|\n",
      "|2606799|   27|\n",
      "| 727242|   25|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identifying the number of movies each user has watched from testing set\n",
    "\n",
    "df_testing.groupBy('userId').count().orderBy(\"count\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "| userId|count|\n",
      "+-------+-----+\n",
      "| 202623|   68|\n",
      "| 482107|   69|\n",
      "|1405451|   69|\n",
      "| 886158|   69|\n",
      "|2474140|   69|\n",
      "|1583736|   69|\n",
      "|1922286|   69|\n",
      "|1714390|   69|\n",
      "|1382057|   69|\n",
      "|1893836|   69|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Identifying the number of movies each user has watched from training set \n",
    "\n",
    "df_training.groupBy('userId').count().orderBy(\"count\", ascending=True).show(10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|   6971|25468|\n",
      "|   6287|24393|\n",
      "|   4640|23525|\n",
      "|   9728|23184|\n",
      "|   8596|23005|\n",
      "|   4432|22565|\n",
      "|  10947|21209|\n",
      "|   6408|21198|\n",
      "|   1202|20997|\n",
      "|  13651|20902|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Movie with Id=6971 has been watched 25468 times \n"
     ]
    }
   ],
   "source": [
    "#Identifying the number of users have watched each movie from training set \n",
    "\n",
    "df_training.groupBy('movieId').count().orderBy(\"count\", ascending=False).show(10)\n",
    "\n",
    "print(\"Movie with Id=6971 has been watched 25468 times \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining the train and test dataframes with the movies dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_joined = df_training.join(df_movies,on=['movieId'],how='inner')\n",
    "\n",
    "df_testing_joined = df_testing.join(df_movies,on=['movieId'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_training_joined)\n",
    "\n",
    "type(df_testing_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------------+--------------------+\n",
      "|movieId| userId|ratings|yearofrelease|               title|\n",
      "+-------+-------+-------+-------------+--------------------+\n",
      "|      8|1744889|    1.0|         2004|What the #$*! Do ...|\n",
      "|      8|1395430|    2.0|         2004|What the #$*! Do ...|\n",
      "|      8|1205593|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8|1488844|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8|1447354|    1.0|         2004|What the #$*! Do ...|\n",
      "|      8| 306466|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8|1331154|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8|1818178|    3.0|         2004|What the #$*! Do ...|\n",
      "|      8| 991725|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8|1987434|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8|1765381|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8| 433803|    3.0|         2004|What the #$*! Do ...|\n",
      "|      8|1148143|    2.0|         2004|What the #$*! Do ...|\n",
      "|      8|1174811|    5.0|         2004|What the #$*! Do ...|\n",
      "|      8|1684516|    3.0|         2004|What the #$*! Do ...|\n",
      "|      8| 754781|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8| 567025|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8|1623132|    4.0|         2004|What the #$*! Do ...|\n",
      "|      8|1567095|    3.0|         2004|What the #$*! Do ...|\n",
      "|      8|1666394|    5.0|         2004|What the #$*! Do ...|\n",
      "+-------+-------+-------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_training_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_schema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-2ad0b7fc4cec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_schema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m's3://netfinal/self-user.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0muser_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_schema' is not defined"
     ]
    }
   ],
   "source": [
    "user_df = sqlContext.read.format('csv').options(header=True, inferSchema=False).schema(df_schema).load('s3://netfinal/self-user.txt')\n",
    "user_df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
