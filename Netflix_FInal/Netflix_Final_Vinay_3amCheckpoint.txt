sc


import pyspark
from pyspark import SparkConf,SparkContext
from pyspark.sql.functions import regexp_extract
from pyspark.sql.types import *
from pyspark.sql import SQLContext

from pyspark.sql.functions import monotonically_increasing_id,row_number 

from pyspark.sql.functions import isnan, count, when, col, desc, udf, col,rand
from pyspark.sql.functions import sort_array, asc, avg
from pyspark.sql.functions import min as Fmin
from pyspark.sql.functions import max as Fmax
from pyspark.sql.functions import stddev as Fstddev
from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler


from pyspark.sql.functions import udf
from pyspark.sql.types import IntegerType

from pyspark.sql import Window

from pyspark.sql.functions import sum as Fsum
from pyspark.sql.functions import rank 
import pyspark.sql.functions as F
from pyspark.sql import DataFrameStatFunctions as statFunc
from pyspark.sql.functions import first
from pyspark.sql.functions import lit

from pyspark.sql.functions import col, countDistinct


import pandas as pd
import matplotlib.pyplot as plt
import sklearn.metrics as metrics
import numpy as np
from sklearn.neighbors import NearestNeighbors
from scipy.spatial.distance import correlation
from sklearn.metrics.pairwise import pairwise_distances
import ipywidgets as widgets
from IPython.display import display, clear_output
from contextlib import contextmanager
import warnings
warnings.filterwarnings('ignore')
import os, sys
import re
import seaborn as sns
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.recommendation import ALS
from pyspark.sql import Row


import pyspark
from pyspark.sql.types import *
from scipy import sparse
from scipy.sparse import csr_matrix



sc = SparkContext.getOrCreate()
sqlContext = SQLContext(sc)





Training_filename ='s3://netflixfinalvin/TrainingRatings.txt'
Testing_filename = 's3://netflixfinalvin/TestingRatings.txt'
Movie_filename = 's3://netflixfinalvin/movie_titles.txt'






movies_df_schema = StructType(
  [StructField('movieId', IntegerType()),
   StructField('yearOfRelease', IntegerType()),
   StructField('title', StringType())]
)
Training_df_schema = StructType(
  [StructField('movieID', IntegerType()),
   StructField('userID', IntegerType()),
   StructField('ratings',DoubleType())]
)

Testing_df_schema = StructType(
  [StructField('movieID', IntegerType()),
   StructField('userID', IntegerType()),
   StructField('ratings',DoubleType())]
)






input_file = "s3://netflixfinalvin/TrainingRatings.txt"
logData = sc.textFile(input_file)


@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@2

#Creating the training,testing and movie dataframes

df_training = sqlContext.read.format('txt').options(inferSchema=True).schema(Training_df_schema).csv(Training_filename)
 
df_testing = sqlContext.read.format('txt').options(inferSchema=True).schema(Testing_df_schema).csv(Testing_filename)
 
df_movies = sqlContext.read.format('txt').options(inferSchema=True).schema(movies_df_schema).csv(Movie_filename)
 



#Count of each dataframes     
training_count = df_training.count()
testing_count = df_testing.count()
movies_count = df_movies.count()


print('There are %s samples in training set , %s samples in testing set and %s samples in movies in the datasets' % (training_count,testing_count, movies_count))
print('Training:')
df_training.show(5)
print('Testing:')
df_testing.show(5)
print('Movies:')
df_movies.show(5,truncate=False)
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

## HOW MANY DISTINCT USERS AND DISTINCT ITEMS ARE THERE IN THE TEST SET ?


#finding out the distinct users in the training set and testing set 

print("The distinct users in training set are :",df_training.select('userID').distinct().count())
print("The distinct users in testing set are :",df_testing.select('userID').distinct().count())



#finding out the distinct items(movies) in the training set and testing set 

print("The distinct items in training set are :",df_training.select('movieID').distinct().count())
print("The distinct items in testing set are :",df_testing.select('movieID').distinct().count())




# Finding Overall Rates for users and Movies in both the sets
## Movie Rating from Training Set




#checking overall rate of the movies  in the training set

Movie_rate_train = df_training.groupBy('movieID')

Movie_rate_train.avg('ratings').orderBy("avg(ratings)", ascending=False).show()









## User Rating from Training Set


User_rate_train = df_training.groupBy('userID')
User_rate_train.avg('ratings').orderBy("avg(ratings)", ascending=False).show()




## Movie Ratings from Testing Set


#checking overall rate of the movies  in the testing set
Movie_rate_test = df_testing.groupBy('movieID')
Movie_rate_test.avg('ratings').orderBy("avg(ratings)", ascending=False).show()




## User Ratings from Testing Set

User_rate_test = df_training.groupBy('userID')
User_rate_test.avg('ratings').orderBy("avg(ratings)", ascending=False).show()




#Identifying the number of users have watched each movie from the testing set

df_testing.groupBy('movieID').count().orderBy("count", ascending=False).show(10)

print("This user has watched this much movies")





#Identifying the number of movies each user has watched from testing set

df_testing.groupBy('userID').count().orderBy("count", ascending=False).show(10)






#Identifying the number of movies each user has watched from training set 

df_training.groupBy('userID').count().orderBy("count", ascending=True).show(10) 





#Identifying the number of users have watched each movie from training set 

df_training.groupBy('movieID').count().orderBy("count", ascending=False).show(10)

print("Movie with Id=6971 has been watched 25468 times ")




type(df_training)





user_movie_rating = df_training.groupBy('userID').pivot('movieID').max('ratings')
user_movie_rating.show()




user_movie_rating.select('6971').show(3)



type(df_training)



# Converting the training pyspark df to pandas df

df_training_pd = df_training.toPandas()


#Pivoting the table with userID as Index and movieID as columns with ratings as the values.

ratings_new = df_training_pd.pivot(index='userID', columns='movieID', values='ratings')

ratings_new.head()




type(train_set)






